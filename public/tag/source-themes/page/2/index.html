<!DOCTYPE html>
<!-- This site was created with Wowchemy. https://www.wowchemy.com -->
<!-- Last Published: October 1, 2024 --><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.7.0 for Hugo" />
  

  
  












  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css" media="print" onload="this.media='all'">

  
  
  
    
    

    
    
    
    
      
      
    
    
    

    
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css" integrity="" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.9783dc0dafeb2e17b28b9a9dd530caa0.css" />

  
  
  

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="/css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>
  

  
  



































  

<meta name="description" content="A highly-customizable Hugo research group theme powered by Wowchemy website builder." />



<link rel="alternate" hreflang="en-us" href="https://robotpilab.github.io/tag/source-themes/" />
<link rel="canonical" href="https://robotpilab.github.io/tag/source-themes/" />



  <link rel="manifest" href="/manifest.webmanifest" />



<link rel="icon" type="image/png" href="/media/icon_hu741267303ece0b55432a717ce280a15e_5637_32x32_fill_lanczos_center_3.png" />
<link rel="apple-touch-icon" type="image/png" href="/media/icon_hu741267303ece0b55432a717ce280a15e_5637_180x180_fill_lanczos_center_3.png" />

<meta name="theme-color" content="#1565c0" />










  
  






<meta property="twitter:card" content="summary" />

  <meta property="twitter:site" content="@wowchemy" />
  <meta property="twitter:creator" content="@wowchemy" />
<meta property="twitter:image" content="https://robotpilab.github.io/media/icon_hu741267303ece0b55432a717ce280a15e_5637_512x512_fill_lanczos_center_3.png" />
<meta property="og:site_name" content="Rice RobotΠ Lab" />
<meta property="og:url" content="https://robotpilab.github.io/tag/source-themes/" />
<meta property="og:title" content="Source Themes | Rice RobotΠ Lab" />
<meta property="og:description" content="A highly-customizable Hugo research group theme powered by Wowchemy website builder." /><meta property="og:image" content="https://robotpilab.github.io/media/icon_hu741267303ece0b55432a717ce280a15e_5637_512x512_fill_lanczos_center_3.png" /><meta property="og:locale" content="en-us" />

  
    <meta property="og:updated_time" content="2024-08-11T20:40:00&#43;00:00" />
  










  
  
  

  
  
    <link rel="alternate" href="/tag/source-themes/index.xml" type="application/rss+xml" title="Rice RobotΠ Lab" />
  

  


  
  <title>Source Themes | Rice RobotΠ Lab</title>

  
  
  
  











</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   "  >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.ec9d49ca50e4b80bdb08f0417a28ed84.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header header--fixed">
  
  
  
  
  












<header>
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/">Rice RobotΠ Lab</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/">Rice RobotΠ Lab</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/project"><span>Projects</span></a>
          </li>

          
          

          

          
          
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/post"><span>News</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/people"><span>People</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/publication"><span>Publications</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/contact"><span>Contact</span></a>
          </li>

          
          

          

          
          
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/join"><span>Join</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        

        
        
        
        <li class="nav-item">
          <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        
        <li class="nav-item dropdown theme-dropdown">
          <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
            <i class="fas fa-moon" aria-hidden="true"></i>
          </a>
          <div class="dropdown-menu">
            <a href="#" class="dropdown-item js-set-theme-light">
              <span>Light</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-dark">
              <span>Dark</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-auto">
              <span>Automatic</span>
            </a>
          </div>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    













  

  
  
  
    
  
<div class="universal-wrapper pt-3">
  <h1>Source Themes</h1>

  

  
</div>



<div class="universal-wrapper">
  


  

  
  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/calculating-the-support-function-of-complex-continuous-surfaces-with-applications-to-minimum-distance-computation-and-optimal-grasp-planning/" >Calculating the Support Function of Complex Continuous Surfaces With Applications to Minimum Distance Computation and Optimal Grasp Planning</a>
    </div>

    
    <a href="/publication/calculating-the-support-function-of-complex-continuous-surfaces-with-applications-to-minimum-distance-computation-and-optimal-grasp-planning/"  class="summary-link">
      <div class="article-style">
        &ldquo;The support function of a surface&rdquo; is a fundamental concept in mathematics and a crucial operation for algorithms in robotics, such as those for collision detection and grasp planning. It is possible to calculate the support function of a convex body in closed form. However, for complex continuous surfaces, especially non-convex ones, this calculation can be far more difficult, and no general solution is available so far. This limits the applicability of related algorithms. This paper presents a branch-and-bound (B&amp;B) algorithm to calculate the support function of complex continuous surfaces. An upper bound of the support function over a surface domain is derived. While a surface domain is divided into subdomains, the upper bound of the support function over any subdomain is proved to be not greater than the one over the original domain. Then, as the B&amp;B algorithm sequentially divides the surface domain by dividing its subdomain having a greater upper bound than the others, the maximum upper bound over all subdomains is monotonically decreasing and converges to the exact value of the desired support function. Furthermore, with the aid of the B&amp;B algorithm, this paper derives new algorithms for the minimum distance between complex continuous surfaces and for globally optimal grasps on objects with continuous surfaces. A number of numerical examples are provided to demonstrate the effectiveness of the proposed algorithms.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      <a href="/author/yu-zheng/">Yu Zheng</a></span>, <span >
      <a href="/author/kaiyu-hang/">Kaiyu Hang</a></span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://hangkaiyu.github.io/pdfs/zheng2020a.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/calculating-the-support-function-of-complex-continuous-surfaces-with-applications-to-minimum-distance-computation-and-optimal-grasp-planning/cite.bib">
  Cite
</a>















    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/object-agnostic-dexterous-manipulation-of-partially-constrained-trajectories/" >Object-Agnostic Dexterous Manipulation of Partially Constrained Trajectories</a>
    </div>

    
    <a href="/publication/object-agnostic-dexterous-manipulation-of-partially-constrained-trajectories/"  class="summary-link">
      <div class="article-style">
        We address the problem of controlling a partially constrained trajectory of the manipulation frame - an arbitrary frame of reference rigidly attached to the object - as the desired motion about this frame is often underdefined. This may be apparent, for example, when the task requires control only about the translational dimensions of the manipulation frame, with disregard to the rotational dimensions. This scenario complicates the computation of the grasp frame trajectory, as the mobility of the mechanism is likely limited due to the constraints imposed by the closed kinematic chain. In this letter, we address this problem by combining a learned, object-agnostic manipulation model of the gripper with Model Predictive Control (MPC). This combination facilitates an approach to simple vision-based control of robotic hands with generalized models, enabling a single manipulation model to extend to different task requirements. By tracking the hand-object configuration through vision, the proposed framework is able to accurately control the trajectory of the manipulation frame along translational, rotational, or mixed trajectories. We provide experiments quantifying the utility of this framework, analyzing its ability to control different objects over varied horizon lengths and optimization iterations, and finally, we implement the controller on a physical system.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      <a href="/author/andrew-s.-morgan/">Andrew S. Morgan</a></span>, <span >
      <a href="/author/kaiyu-hang/">Kaiyu Hang</a></span>, <span >
      <a href="/author/aaron-m.-dollar/">Aaron M. Dollar</a></span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://hangkaiyu.github.io/pdfs/morgan2020b.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/object-agnostic-dexterous-manipulation-of-partially-constrained-trajectories/cite.bib">
  Cite
</a>















    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/end-to-end-nonprehensile-rearrangement-with-deep-reinforcement-learning-and-simulation-to-reality-transfer/" >End-to-End Nonprehensile Rearrangement with Deep Reinforcement Learning and Simulation-to-Reality Transfer</a>
    </div>

    
    <a href="/publication/end-to-end-nonprehensile-rearrangement-with-deep-reinforcement-learning-and-simulation-to-reality-transfer/"  class="summary-link">
      <div class="article-style">
        Nonprehensile rearrangement is the problem of controlling a robot to interact with objects through pushing actions in order to reconfigure the objects into a predefined goal pose. In this work, we rearrange one object at a time in an environment with obstacles using an end-to-end policy that maps raw pixels as visual input to control actions without any form of engineered feature extraction. To reduce the amount of training data that needs to be collected using a real robot, we propose a simulation-to-reality transfer approach. In the first step, we model the nonprehensile rearrangement task in simulation and use deep reinforcement learning to learn a suitable rearrangement policy, which requires hundreds of thousands of example actions for training. Thereafter, we collect a small dataset of only 70 episodes of real-world actions as supervised examples for adapting the learned rearrangement policy to real-world input data. In this process, we make use of newly proposed strategies for improving the reinforcement learning process, such as heuristic exploration and the curation of a balanced set of experiences. We evaluate our method in both simulation and real settings using a Baxter robot to show that the proposed approach can effectively improve the training process in simulation, as well as efficiently adapt the learned policy to the real-world application, even when the camera pose is different from simulation. Additionally, we show that the learned system can not only provide adaptive behavior to handle unforeseen events during executions, such as distracting objects, sudden changes in the positions of the objects, and obstacles, but also can deal with obstacle shapes that were not present in the training process.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      <a href="/author/weihao-yuan/">Weihao Yuan</a></span>, <span >
      <a href="/author/kaiyu-hang/">Kaiyu Hang</a></span>, <span >
      <a href="/author/danica-kragic/">Danica Kragic</a></span>, <span >
      <a href="/author/michael-y.-wang/">Michael Y. Wang</a></span>, <span >
      <a href="/author/johannes-a.-stork/">Johannes A. Stork</a></span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://hangkaiyu.github.io/pdfs/yuan2019b.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/end-to-end-nonprehensile-rearrangement-with-deep-reinforcement-learning-and-simulation-to-reality-transfer/cite.bib">
  Cite
</a>















    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/pre-grasp-sliding/" >Pre-Grasp Sliding Manipulation of Thin Objects Using Soft, Compliant, or Underactuated Hands</a>
    </div>

    
    <a href="/publication/pre-grasp-sliding/"  class="summary-link">
      <div class="article-style">
        We address the problem of pre-grasp sliding manipulation, which is an essential skill when a thin object cannot be directly grasped from a flat surface. Leveraging the passive reconfigurability of soft, compliant, or underactuated robotic hands, we formulate this problem as an integrated motion and grasp planning problem and plan the manipulation directly in the robot configuration space. Instead of explicitly precomputing a pair of valid start and goal configurations and then planning a path to connect them in a separate step, our planner actively samples start and goal robot configurations from configuration sampleable regions modeled from the geometries of the object and support surface. While randomly connecting the sampled start and goal configurations in pairs, the planner verifies whether any connected pair can achieve the task to finally confirm a solution. The proposed planner is implemented and evaluated both in simulation and on a real robot. Given the inherent compliance of the employed Yale T42 hand, we relax the motion constraints and show that the planning performance is significantly boosted. Moreover, we show that our planner outperforms two baseline planners and that it can deal with objects and support surfaces of arbitrary geometries and sizes.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      <a href="/author/kaiyu-hang/">Kaiyu Hang</a></span>, <span >
      <a href="/author/andrew-s.-morgan/">Andrew S. Morgan</a></span>, <span >
      <a href="/author/aaron-m.-dollar/">Aaron M. Dollar</a></span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://hangkaiyu.github.io/pdfs/hang2019a.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/pre-grasp-sliding/cite.bib">
  Cite
</a>















    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/hand-object-configuration-estimation-using-particle-filters-for-dexterous-in-hand-manipulation/" >Hand-object configuration estimation using particle filters for dexterous in-hand manipulation</a>
    </div>

    
    <a href="/publication/hand-object-configuration-estimation-using-particle-filters-for-dexterous-in-hand-manipulation/"  class="summary-link">
      <div class="article-style">
        We consider the problem of dexterous manipulation with a focus on unknown or uncertain hand-object parameters, such as hand configuration, object pose within the hand, and contact positions. In this work, we formulate a generic framework for hand-object configuration estimation using underactuated hands as an example. Due to the passive reconfigurability and lack of encoders in the hand&rsquo;s joints, it is challenging to estimate, plan, and actively control underactuated manipulation. By modeling the grasp constraints, we present a particle filter-based framework to estimate the hand configuration. Specifically, given an arbitrary grasp, we start by sampling a set of hand configuration hypotheses and then randomly manipulate the object within the hand. While observing the object&rsquo;s movements as evidence using an external camera, which is not necessarily calibrated with the hand frame, our estimator calculates the likelihood of each hypothesis to iteratively estimate the hand configuration. Once converged, the estimator is used to track the hand configuration in real-time for future manipulations. Thereafter, we develop an algorithm to precisely plan and control the underactuated manipulation to move the grasped object to desired poses. In contrast to most other dexterous manipulation approaches, our framework does not require any tactile sensing or joint encoders and can directly operate on any novel objects without requiring a model of the object a priori. We implemented our framework on both the Yale Model O hand and the Yale T42 hand. The results show that the estimation is accurate for different objects and that the framework can be easily adapted across different underactuated hand models. Finally, we evaluated our planning and control algorithm with handwriting tasks and demonstrated the effectiveness of the proposed framework.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      <a href="/author/kaiyu-hang/">Kaiyu Hang</a></span>, <span >
      <a href="/author/walter-g.-bircher/">Walter G. Bircher</a></span>, <span >
      <a href="/author/andrew-s.-morgan/">Andrew S. Morgan</a></span>, <span >
      <a href="/author/and-aaron-m.-dollar/">and Aaron M. Dollar</a></span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://hangkaiyu.github.io/pdfs/hang2019c.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/hand-object-configuration-estimation-using-particle-filters-for-dexterous-in-hand-manipulation/cite.bib">
  Cite
</a>















    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/benchmarking-protocol-for-grasp-planning-algorithms/" >Benchmarking Protocol for Grasp Planning Algorithms</a>
    </div>

    
    <a href="/publication/benchmarking-protocol-for-grasp-planning-algorithms/"  class="summary-link">
      <div class="article-style">
        Numerous grasp planning algorithms have been proposed since the 1980s. The grasping literature has expanded rapidly in recent years, building on greatly improved vision systems and computing power. Methods have been proposed to plan stable grasps on known objects (exact 3D model is available), familiar objects (e.g. exploiting a-priori known grasps for different objects of the same category), or novel object shapes observed during task execution. Few of these methods have ever been compared in a systematic way, and objective performance evaluation of such complex systems remains problematic. Difficulties and confounding factors include different assumptions and amounts of a-priori knowledge in different algorithms, different robots, hands, vision systems, and setups in different labs, and different choices or application needs for grasped objects. Also, grasp planning can use different grasp quality metrics (including empirical or theoretical stability measures), or other criteria, e.g. computational speed, or combination of grasps with reachability considerations. While acknowledging and discussing the outstanding difficulties surrounding this complex topic, we propose a methodology for reproducible experiments to compare the performance of a variety of grasp planning algorithms. Our protocol attempts to improve the objectivity with which different grasp planners are compared by minimizing the influence of key components in the grasping pipeline, e.g. vision and pose estimation. The protocol is demonstrated by evaluating two different grasp planners: a state-of-the-art model-free planner and a popular open-source model-based planner. We show results from real-robot experiments with a 7-DoF arm and 2-finger hand and simulation-based evaluations.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      <a href="/author/yasemin-bekiroglu/">Yasemin Bekiroglu</a></span>, <span >
      <a href="/author/naresh-marturi/">Naresh Marturi</a></span>, <span >
      <a href="/author/maximo-a.-roa/">Maximo A. Roa</a></span>, <span >
      <a href="/author/maxime-adjigble/">Maxime Adjigble</a></span>, <span >
      <a href="/author/tommaso-pardi/">Tommaso Pardi</a></span>, <span >
      <a href="/author/cindy-grimm/">Cindy Grimm</a></span>, <span >
      <a href="/author/ravi-balasubramanian/">Ravi Balasubramanian</a></span>, <span >
      <a href="/author/kaiyu-hang/">Kaiyu Hang</a></span>, <span >
      <a href="/author/rustam-stolkin/">Rustam Stolkin</a></span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://hangkaiyu.github.io/pdfs/bekiroglu2019a.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/benchmarking-protocol-for-grasp-planning-algorithms/cite.bib">
  Cite
</a>















    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/perching-and-resting-a-paradigm-for-uav-maneuvering-with-modularized-landing-gears/" >Perching and resting -- A paradigm for UAV maneuvering with modularized landing gears</a>
    </div>

    
    <a href="/publication/perching-and-resting-a-paradigm-for-uav-maneuvering-with-modularized-landing-gears/"  class="summary-link">
      <div class="article-style">
        Perching helps small unmanned aerial vehicles (UAVs) extend their time of operation by saving battery power. However, most strategies for UAV perching require complex maneuvering and rely on specific structures, such as rough walls for attaching or tree branches for grasping. Many strategies to perching neglect the UAV’s mission such that saving battery power interrupts the mission. We suggest enabling UAVs with the capability of making and stabilizing contacts with the environment, which will allow the UAV to consume less energy while retaining its altitude, in addition to the perching capability that has been proposed before. This new capability is termed “resting.” For this, we propose a modularized and actuated landing gear framework that allows stabilizing the UAV on a wide range of different structures by perching and resting. Modularization allows our framework to adapt to specific structures for resting through rapid prototyping with additive manufacturing. Actuation allows switching between different modes of perching and resting during flight and additionally enables perching by grasping. Our results show that this framework can be used to perform UAV perching and resting on a set of common structures, such as street lights and edges or corners of buildings. We show that the design is effective in reducing power consumption, promotes increased pose stability, and preserves large vision ranges while perching or resting at heights. In addition, we discuss the potential applications facilitated by our design, as well as the potential issues to be addressed for deployment in practice.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      <a href="/author/kaiyu-hang/">Kaiyu Hang</a></span>, <span >
      <a href="/author/ximin-lyu/">Ximin Lyu</a></span>, <span >
      <a href="/author/haoran-song/">Haoran Song</a></span>, <span >
      <a href="/author/johannes-a.-stork/">Johannes A. Stork</a></span>, <span >
      <a href="/author/aaron-m.-dollar/">Aaron M. Dollar</a></span>, <span >
      <a href="/author/danica-kragic/">Danica Kragic</a></span>, <span >
      <a href="/author/fu-zhang/">Fu Zhang</a></span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://hangkaiyu.github.io/perching.html" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/perching-and-resting-a-paradigm-for-uav-maneuvering-with-modularized-landing-gears/cite.bib">
  Cite
</a>















    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/fingertip-surface/" >Fingertip Surface Optimization for Robust Grasping on Contact Primitives</a>
    </div>

    
    <a href="/publication/fingertip-surface/"  class="summary-link">
      <div class="article-style">
        We address the problem of designing fingertips by leveraging the fact that most grasp contacts share a few classes of local geometries. In order to maximize the contact areas and achieve more robust grasps, we first define the concept of a Contact Primitive, which represents a set of contacts with similar local geometries. Thereafter, we propose a uniform cost algorithm, formulated as a decision-making process in a tree structure, to cluster a set of example grasp contacts into a finite set of Contact Primitives. We design fingertips by optimizing to match the local geometry of each contact primitive and then 3D print them using soft materials to compensate for optimization residuals. For novel objects, we provide an efficient algorithm to generate grasp contacts that match the fingertip geometries while forming stable grasps. Comparing to a baseline of flat fingertip design, the experimental results show that our design significantly improves grasp stability and is more robust against various uncertainties.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      <a href="/author/haoran-song/">Haoran Song</a></span>, <span >
      <a href="/author/michael-y.-wang/">Michael Y. Wang</a></span>, <span >
      <a href="/author/kaiyu-hang/">Kaiyu Hang</a></span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://hangkaiyu.github.io/pdfs/song2018a.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/fingertip-surface/cite.bib">
  Cite
</a>















    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/a-framework/" >A Framework For Optimal Grasp Contact Planning</a>
    </div>

    
    <a href="/publication/a-framework/"  class="summary-link">
      <div class="article-style">
        <p>We consider the problem of finding optimal grasp contacts for arbitrary objects, based on a given grasp quality function. Our approach formulates a framework for contact-level grasping as a path-finding problem in the space of super-contact grasps. The initial super-contact grasp contains all grasps, and in each step along a path, grasps are removed. To achieve this, we introduce and formally characterize search space structure and cost functions, under which minimal cost paths correspond to optimal grasps. Our formulation avoids expensive exhaustive search and reduces computational cost by several orders of magnitude.</p>
<p>We present admissible heuristic functions and exploit approximate heuristic search to further reduce computational cost while maintaining bounded sub-optimality for resulting grasps. We exemplify our formulation with point-contact grasping, for which we define domain-specific heuristics and demonstrate optimality and bounded sub-optimality by comparing against exhaustive and uniform cost search on example objects. Furthermore, we explain how to restrict the search graph to satisfy grasp constraints for modeling hand kinematics. We also analyze our algorithm empirically in terms of created and visited search states and resultant effective branching factor.</p>

      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      <a href="/author/kaiyu-hang/">Kaiyu Hang</a></span>, <span >
      <a href="/author/johannes-a.-stork/">Johannes A. Stork</a></span>, <span >
      <a href="/author/nancy-s.-pollard/">Nancy S. Pollard</a></span>, <span >
      <a href="/author/danica-kragic/">Danica Kragic</a></span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://hangkaiyu.github.io/pdfs/hang2017a.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/a-framework/cite.bib">
  Cite
</a>















    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/dexterous-grasping-under-shape-uncertainty/" >Dexterous Grasping under Shape Uncertainty</a>
    </div>

    
    <a href="/publication/dexterous-grasping-under-shape-uncertainty/"  class="summary-link">
      <div class="article-style">
        An important challenge in robotics is achieving robust performance in object grasping and manipulation while dealing with noise and uncertainty. This paper presents an approach for addressing the performance of dexterous grasping under shape uncertainty. In our approach, the uncertainty in the object&rsquo;s shape is parameterized and incorporated as a constraint into grasp planning. The proposed approach is used to plan feasible hand configurations for realizing planned contacts using different robotic hands. A compliant finger closing scheme is devised by exploiting both the object&rsquo;s shape uncertainty and tactile sensing at the fingertips. Experimental evaluation demonstrates that our method improves the performance of dexterous grasping under shape uncertainty.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      <a href="/author/miao-li/">Miao Li</a></span>, <span >
      <a href="/author/kaiyu-hang/">Kaiyu Hang</a></span>, <span >
      <a href="/author/danica-kragic/">Danica Kragic</a></span>, <span >
      <a href="/author/aude-billard/">Aude Billard</a></span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://hangkaiyu.github.io/pdfs/miao2015a.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/dexterous-grasping-under-shape-uncertainty/cite.bib">
  Cite
</a>















    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

  

  

  
<nav class="mt-1">
  <ul class="pagination justify-content-center">
    
    <li class="page-item"><a class="page-link" href="/tag/source-themes/">&laquo;</a></li>
    
    
    <li class="page-item"><a class="page-link" href="/tag/source-themes/page/3/">&raquo;</a></li>
    
  </ul>
</nav>


</div>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  












  
  
  
  
  













  





  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-themes" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  


<script src="/js/vendor-bundle.min.32ee83730ed883becad04bc5170512cc.js"></script>




  

  
  

  






  <script src="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js" integrity="" crossorigin="anonymous"></script>








  
  <script id="search-hit-fuse-template" type="text/x-template">
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script>
  
    <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
  












  
  
  
  
  
  
  







<script id="page-data" type="application/json">{"use_headroom":true}</script>



  <script src="/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js" type="module"></script>









  
  


<script src="/en/js/wowchemy.min.53e2d4aa5b5aee6f858cf53dc1025ec4.js"></script>



  <script src="/js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js" type="module"></script>




  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        
        <pre><code></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


  <script src="/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js" type="module"></script>


















</body>
</html>
