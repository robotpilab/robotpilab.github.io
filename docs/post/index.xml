<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Latest News | Rice RobotΠ Lab</title>
    <link>https://robotpilab.github.io/post/</link>
      <atom:link href="https://robotpilab.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Latest News</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 07 Jul 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://robotpilab.github.io/media/icon_hu741267303ece0b55432a717ce280a15e_5637_512x512_fill_lanczos_center_3.png</url>
      <title>Latest News</title>
      <link>https://robotpilab.github.io/post/</link>
    </image>
    
    <item>
      <title>Our Paper &#34;Interactive Robot-Environment Self-Calibration via Compliant Exploratory Actions&#34; accepted by IEEE/RSJ IROS 2024</title>
      <link>https://robotpilab.github.io/post/self_cali_iros_24/</link>
      <pubDate>Sun, 07 Jul 2024 00:00:00 +0000</pubDate>
      <guid>https://robotpilab.github.io/post/self_cali_iros_24/</guid>
      <description>&lt;!--StartFragment--&gt;
&lt;p&gt;Our paper &lt;a href=&#34;https://arxiv.org/abs/2403.13144&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Interactive Robot-Environment Self-Calibration via Compliant Exploratory Actions&amp;rdquo; &lt;/a&gt; has been accepted by IEEE/RSJ IEEE International Conference on Intelligent Robots and Systems (IEEE/RSJ IROS) 2024.  Check out the &lt;a href=&#34;https://youtu.be/NiDBvtswzV4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;video&lt;/a&gt;!&lt;/p&gt;
&lt;!--EndFragment--&gt;</description>
    </item>
    
    <item>
      <title>Our Paper &#34;UNO Push, Unified Nonprehensile Object Pushing via Non-Parametric Estimation and Model Predictive Control&#34; accepted by IEEE/RSJ IROS 2024</title>
      <link>https://robotpilab.github.io/post/uno_push_iros_24/</link>
      <pubDate>Sun, 07 Jul 2024 00:00:00 +0000</pubDate>
      <guid>https://robotpilab.github.io/post/uno_push_iros_24/</guid>
      <description>&lt;!--StartFragment--&gt;
&lt;p&gt;Our paper &lt;a href=&#34;https://arxiv.org/abs/2403.13274&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;UNO Push: Unified Nonprehensile Object Pushing via Non-Parametric Estimation and Model Predictive Control&amp;rdquo; &lt;/a&gt; has been accepted by IEEE/RSJ IEEE International Conference on Intelligent Robots and Systems (IEEE/RSJ IROS) 2024.  Check out the &lt;a href=&#34;https://www.youtube.com/watch?v=MLzGTxhKs6E&amp;amp;t=1s&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;video&lt;/a&gt;!&lt;/p&gt;
&lt;!--EndFragment--&gt;</description>
    </item>
    
    <item>
      <title>Howard Qian Awarded &#34;Distinction in Research and Creative Works&#34; by Rice University</title>
      <link>https://robotpilab.github.io/post/howard_award/</link>
      <pubDate>Thu, 25 Apr 2024 00:00:00 +0000</pubDate>
      <guid>https://robotpilab.github.io/post/howard_award/</guid>
      <description>&lt;!--StartFragment--&gt;
&lt;p&gt;We are thrilled to announce that our esteemed lab member, Howard Qian, has been awarded the prestigious &amp;ldquo;Distinction in Research and Creative Works&amp;rdquo; by Rice University.&lt;/p&gt;
&lt;p&gt;This is a university honor for graduating students that will be granted at Commencement and will appear on recipients&amp;rsquo; transcripts and diplomas. To apply, CS students should submit a work or body of work that illustrates creativity, self-initiation, independence, perseverance, and dedication. In all cases, we expect that students who apply for distinction in undergraduate research in computer science will have produced something that goes beyond the traditional expectations of their coursework.&lt;/p&gt;
&lt;p&gt;For Computer Science students, the application process involves submitting a work or body of work that goes beyond the traditional expectations of coursework. Howard&amp;rsquo;s successful application cited his contributions to the RISeg paper, with his first authorship and the paper&amp;rsquo;s acceptance to ICRA being key factors in receiving this honor.&lt;/p&gt;
&lt;p&gt;This award underscores the high-quality research being conducted in our lab and highlights Howard&amp;rsquo;s exceptional contributions to the field. We congratulate Howard on this well-deserved recognition and look forward to his continued success in future endeavors.&lt;/p&gt;
&lt;!--EndFragment--&gt;</description>
    </item>
    
    <item>
      <title>Our Paper &#34;RISeg, Robot Interactive Object Segmentation via Body Frame-Invariant Features&#34; accepted by IEEE-RAS ICRA 2024, as well as its 3DVRM workshop</title>
      <link>https://robotpilab.github.io/post/riseg_icra_24/</link>
      <pubDate>Sat, 02 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://robotpilab.github.io/post/riseg_icra_24/</guid>
      <description>&lt;!--StartFragment--&gt;
&lt;p&gt;Our paper &lt;a href=&#34;https://arxiv.org/abs/2403.01731&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;RISeg: Robot Interactive Object Segmentation via Body Frame-Invariant Features&amp;rdquo; &lt;/a&gt; has been accepted by IEEE-RAS International Conference on Robotics and Automation (IEEE-RAS ICRA).  Check out the &lt;a href=&#34;https://www.youtube.com/watch?v=K_FU310Jm1k&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;video&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;RISeg was also recently accepted to the &lt;a href=&#34;https://3d-manipulation-workshop.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;3DVRM workshop&amp;rdquo; &lt;/a&gt; at ICRA!&lt;/p&gt;
&lt;p&gt;RISeg is an interactive perception framework in which robot actions are selected based on a scene&amp;rsquo;s uncertainty heatmap representation and object segmentation is improved via a body frame-invariant feature.&lt;/p&gt;
&lt;p&gt;In order to successfully perform manipulation tasks in new environments, such as grasping, robots must be proficient in segmenting unseen objects from the background and/or other objects. Previous works perform unseen object instance segmentation (UOIS) by training deep neural networks on large-scale data to learn RGB/RGB-D feature embeddings, where cluttered environments often result in inaccurate segmentations. We build upon these methods and introduce a novel approach to correct inaccurate segmentation, such as under-segmentation, of static image-based UOIS masks by using robot interaction and a designed body frame-invariant feature. We demonstrate that the relative linear and rotational velocities of frames randomly attached to rigid bodies due to robot interactions can be used to identify objects and accumulate corrected object-level segmentation masks. By introducing motion to regions of segmentation uncertainty, we are able to drastically improve segmentation accuracy in an uncertainty-driven manner with minimal, non-disruptive interactions (ca. 2-3 per scene). We demonstrate the effectiveness of our proposed interactive perception pipeline in accurately segmenting cluttered scenes by achieving an average object segmentation accuracy rate of 80.7%, an increase of 28.2% when compared with other state-of-the-art UOIS methods.&lt;/p&gt;
&lt;!--EndFragment--&gt;</description>
    </item>
    
    <item>
      <title>In-Hand Manipulation Competition in the 9th RGMC</title>
      <link>https://robotpilab.github.io/post/rgmc/</link>
      <pubDate>Thu, 08 Feb 2024 23:13:00 +0000</pubDate>
      <guid>https://robotpilab.github.io/post/rgmc/</guid>
      <description>&lt;!--StartFragment--&gt;
&lt;p&gt;We are organizing the &lt;a href=&#34;https://www.cse.usf.edu/~yusun/rgmc/2024.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;9th Robotic Grasping and Manipulation Competition (RGMC)&lt;/a&gt; at IEEE-RAS ICRA 2024 in Yokohama, Japan, on May 13-17. Dr. Hang is the lead organizer of the &lt;a href=&#34;https://hangkaiyu.github.io/RGMC_in_hand_manipulation_subtrack.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;In-Hand Manipulation Competition (Sub-Track 2)&lt;/a&gt; within the Essential Skill Track. We look forward to seeing everyone in the competition!&lt;/p&gt;
&lt;!--EndFragment--&gt;</description>
    </item>
    
    <item>
      <title>National Science Foundation CAREER Award</title>
      <link>https://robotpilab.github.io/post/national-science-foundation-career-award/</link>
      <pubDate>Thu, 29 Jun 2023 22:08:14 +0000</pubDate>
      <guid>https://robotpilab.github.io/post/national-science-foundation-career-award/</guid>
      <description>&lt;p&gt;Kaiyu Hang has won a &lt;a href=&#34;https://news.rice.edu/news/2023/rice-us-kaiyu-hang-wins-nsf-career-award&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;National Science Foundation CAREER Award&lt;/a&gt; to develop robots that can physically interact with the world through compliance- and motion-based manipulation funnels.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Rice CS team helps robots rearrange objects without gripping them</title>
      <link>https://robotpilab.github.io/post/kejia-ren/</link>
      <pubDate>Thu, 22 Jun 2023 22:08:14 +0000</pubDate>
      <guid>https://robotpilab.github.io/post/kejia-ren/</guid>
      <description>&lt;p&gt;Rice University Computer Scientists presented research on &lt;a href=&#34;https://csweb.rice.edu/news/rice-cs-team-helps-robots-rearrange-objects-without-gripping-them&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;enabling robots to rearrange objects without grasping them&lt;/a&gt; at the 2023 International Conference on Robotics and Automation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Our Paper &#34;Non-Parametric Self-Identification and Model Predictive Control of Dexterous In-Hand Manipulation&#34; has been accepted by IEEE/RSJ IROS</title>
      <link>https://robotpilab.github.io/post/paper-non-parametric-self-identification/</link>
      <pubDate>Wed, 21 Jun 2023 22:10:07 +0000</pubDate>
      <guid>https://robotpilab.github.io/post/paper-non-parametric-self-identification/</guid>
      <description>&lt;!--StartFragment--&gt;
&lt;p&gt;Our paper &lt;a href=&#34;https://arxiv.org/abs/2307.10033&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Non-Parametric Self-Identification and Model Predictive Control of Dexterous In-Hand Manipulation&amp;rdquo; &lt;/a&gt;has been accepted by IEEE/RSJ IEEE International Conference on Intelligent Robots and Systems (IEEE/RSJ IROS). Check out the &lt;a href=&#34;https://youtu.be/4FQ2193q1kk&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;video&lt;/a&gt;!&lt;/p&gt;
&lt;!--EndFragment--&gt;</description>
    </item>
    
    <item>
      <title>Our Paper &#34;Self-Supervised Unseen Object Instance Segmentation via Long-Term Robot Interaction&#34; accepted by RSS 2023</title>
      <link>https://robotpilab.github.io/post/20-12-01-wowchemy-prize/</link>
      <pubDate>Thu, 02 Mar 2023 06:00:00 +0000</pubDate>
      <guid>https://robotpilab.github.io/post/20-12-01-wowchemy-prize/</guid>
      <description>&lt;p&gt;Our paper &lt;a href=&#34;https://arxiv.org/abs/2302.03793&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Self-Supervised Unseen Object Instance Segmentation via Long-Term Robot Interaction&amp;rdquo; &lt;/a&gt; has been accepted by Robotics: Science and Systems (RSS 2023). Check out the &lt;a href=&#34;https://youtu.be/_ykvsRAXRT0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;video&lt;/a&gt;!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Workshop on &#34;Compliant Robot Manipulation: Challenges and New Opportunities&#34; in IEEE-RAS ICRA 2023</title>
      <link>https://robotpilab.github.io/post/workshop-on-compliant-robot-manipulation-challenges-and-new-opportunities-in-ieee-ras-icra-2023/</link>
      <pubDate>Thu, 22 Dec 2022 23:11:32 +0000</pubDate>
      <guid>https://robotpilab.github.io/post/workshop-on-compliant-robot-manipulation-challenges-and-new-opportunities-in-ieee-ras-icra-2023/</guid>
      <description>&lt;!--StartFragment--&gt;
&lt;p&gt;In IEEE-RAS ICRA 2023, we will organize the second workshop on &lt;strong&gt;&amp;ldquo;Compliant Robot Manipulation: Challenges and New Opportunities&amp;rdquo;&lt;/strong&gt;. Distinguished speakers from both academia and industry will join to share their brilliant research progress and throughts. Poster contributions with oral presentation opportunities will be an important part of the workshop. Please read more details &lt;a href=&#34;https://sites.google.com/yale.edu/icra2023-compliantmanipulation/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here &lt;/a&gt;.&lt;/p&gt;
&lt;!--EndFragment--&gt;</description>
    </item>
    
    <item>
      <title>Our Paper &#34;Kinodynamic Rapidly-exploring Random Forest for Rearrangement-Based Nonprehensile Manipulation&#34; accepted by IEEE-RAS ICRA 2023</title>
      <link>https://robotpilab.github.io/post/20-12-02-icml-best-paper/</link>
      <pubDate>Fri, 02 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://robotpilab.github.io/post/20-12-02-icml-best-paper/</guid>
      <description>&lt;!--StartFragment--&gt;
&lt;p&gt;Our paper &lt;a href=&#34;https://arxiv.org/abs/2302.04360&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Kinodynamic Rapidly-exploring Random Forest for Rearrangement-Based Nonprehensile Manipulation&amp;rdquo; &lt;/a&gt;has been accepted by IEEE-RAS International Conference on Robotics and Automation (IEEE-RAS ICRA).  Check out the &lt;a href=&#34;https://youtu.be/xf6N-a95YKQ&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;video&lt;/a&gt;!&lt;/p&gt;
&lt;!--EndFragment--&gt;</description>
    </item>
    
    <item>
      <title>Robot Self-Identification selected by Science Robotics as the Top 5 Editor&#39;s Picks of 2021</title>
      <link>https://robotpilab.github.io/post/robot-self-identification-selected-by-science-robotics-as-the-top-5-editors-picks-of-2021/</link>
      <pubDate>Fri, 17 Dec 2021 23:13:00 +0000</pubDate>
      <guid>https://robotpilab.github.io/post/robot-self-identification-selected-by-science-robotics-as-the-top-5-editors-picks-of-2021/</guid>
      <description>&lt;!--StartFragment--&gt;
&lt;p&gt;Our work on &lt;a href=&#34;https://hangkaiyu.github.io/self-identification.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Robot Self-Identification &lt;/a&gt;has been selected by Science Robotics as the &lt;strong&gt;Top 5 Editor&amp;rsquo;s Picks of 2021&lt;/strong&gt;! Read &lt;a href=&#34;https://sci.scientific-direct.net/view_online.asp?1728038&amp;amp;c0c33e0cc4c44232&amp;amp;18&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Here &lt;/a&gt;.&lt;/p&gt;
&lt;!--EndFragment--&gt;</description>
    </item>
    
  </channel>
</rss>
